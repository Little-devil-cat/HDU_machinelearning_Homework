from math import log
import operator
import copy


def calcShannonEnt(dataSet):
    numEntires = len(dataSet)  # è¿”å›žæ•°æ®é›†çš„è¡Œæ•°
    labelCounts = {}  # ä¿å­˜æ¯ä¸ªæ ‡ç­¾(Label)å‡ºçŽ°æ¬¡æ•°çš„å­—å…¸
    for featVec in dataSet:  # å¯¹æ¯ç»„ç‰¹å¾å‘é‡è¿›è¡Œç»Ÿè®¡
        currentLabel = featVec[-1]  # æå–æ ‡ç­¾(Label)ä¿¡æ¯
        if currentLabel not in labelCounts.keys():  # å¦‚æžœæ ‡ç­¾(Label)æ²¡æœ‰æ”¾å…¥ç»Ÿè®¡æ¬¡æ•°çš„å­—å…¸,æ·»åŠ è¿›åŽ»
            labelCounts[currentLabel] = 0
        labelCounts[currentLabel] += 1  # Labelè®¡æ•°
    shannonEnt = 0.0  # ç»éªŒç†µ
    for key in labelCounts:  # è®¡ç®—é¦™å†œç†µ
        prob = float(labelCounts[key]) / numEntires  # é€‰æ‹©è¯¥æ ‡ç­¾(Label)çš„æ¦‚çŽ‡
        shannonEnt -= prob * log(prob, 2)  # åˆ©ç”¨å…¬å¼è®¡ç®—
    return shannonEnt  # è¿”å›žç»éªŒç†µ


def splitDataSet(dataSet, axis, value):
    result = []
    for data in dataSet:
        if data[axis] == value:  # å¦‚æžœè¯¥è¡Œæ•°æ®axisåˆ—çš„å€¼ä¸ºvalue
            r = data[:axis] + data[axis + 1:]  # å°±æŠŠè¿™ä¸€è¡Œé™¤axisåˆ—ä»¥å¤–çš„å…ƒç´ æ”¾å…¥r
            result.append(r)  # æ„æ€å°±æ˜¯ï¼Œå½“å‰æ˜¯ä»¥axisåˆ—çš„ç‰¹å¾ä½œä¸ºå†³ç­–æ ‘åˆ†æ”¯æ ‡å‡†çš„ï¼Œ
    return result



def chooseBestFeatureToSplit(dataSet):
    numFeatures = len(dataSet[0]) - 1  # ç‰¹å¾æ•°é‡
    baseEntropy = calcShannonEnt(dataSet)  # è®¡ç®—æ•°æ®é›†çš„é¦™å†œç†µ
    bestInfoGain = 0.0  # ä¿¡æ¯å¢žç›Šï¼ˆçŽ‡ï¼‰
    bestFeature = -1  # æœ€ä¼˜ç‰¹å¾çš„ç´¢å¼•å€¼
    A = []

    for i in range(numFeatures):  # éåŽ†æ‰€æœ‰ç‰¹å¾
        # èŽ·å–dataSetçš„ç¬¬iä¸ªæ‰€æœ‰ç‰¹å¾
        featList = [example[i] for example in dataSet]
        uniqueVals = set(featList)  # åˆ›å»ºseté›†åˆ{},å…ƒç´ ä¸å¯é‡å¤
        newEntropy = 0.0  # ç»éªŒæ¡ä»¶ç†µ
        ibaseEntroy = 0.0  # æ•°æ®é›†dataSetå…³äºŽç‰¹å¾içš„å€¼çš„ç†µ
        for value in uniqueVals:  # è®¡ç®—ä¿¡æ¯å¢žç›Š
            subDataSet = splitDataSet(dataSet, i, value)  # subDataSetåˆ’åˆ†åŽçš„å­é›†
            prob = len(subDataSet) / float(len(dataSet))  # è®¡ç®—å­é›†çš„æ¦‚çŽ‡
            newEntropy += prob * calcShannonEnt(subDataSet)  # æ ¹æ®å…¬å¼è®¡ç®—ç»éªŒæ¡ä»¶ç†µ
            ibaseEntroy -= prob * log(prob, 2)
        infoGain = baseEntropy - newEntropy  # ä¿¡æ¯å¢žç›Š
        C = [0, 0]
        C[0] = i
        C[1] = infoGain
        A.append(C)
        infoGainRatio = (baseEntropy - newEntropy) / ibaseEntroy  # æŒ‰ç…§iç‰¹å¾åˆ’åˆ†çš„ä¿¡æ¯å¢žç›Šæ¯”
        print("ç¬¬%dä¸ªç‰¹å¾çš„å¢žç›Šä¸º%.3f" % (i, infoGain))  # æ‰“å°æ¯ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢žç›Š
        if (infoGain > bestInfoGain):  # è®¡ç®—ä¿¡æ¯å¢žç›Š
            bestInfoGain = infoGainRatio  # æ›´æ–°ä¿¡æ¯å¢žç›Šï¼Œæ‰¾åˆ°æœ€å¤§çš„ä¿¡æ¯å¢žç›ŠçŽ‡
            bestFeature = i  # è®°å½•ä¿¡æ¯å¢žç›Šæœ€å¤§çš„ç‰¹å¾çš„ç´¢å¼•å€¼
    return bestFeature  # è¿”å›žä¿¡æ¯å¢žç›Šæœ€å¤§çš„ç‰¹å¾çš„ç´¢å¼•å€¼


def chooseBestFeatureToSplit_rate(dataSet):
    numFeatures = len(dataSet[0]) - 1  # ç‰¹å¾ä¸ªæ•°ï¼Œé™¤åŽ»æœ€åŽä¸€åˆ—çš„åˆ†ç±»æ ‡ç­¾
    ent = calcShannonEnt(dataSet)  # å½“å‰æ•°æ®é›†çš„ä¿¡æ¯ç†µ
    best_gain = 0.0  # æœ€ä½³ä¿¡æ¯ç†µ
    best_feature_id = -1  # æœ€ä½³ä¿¡æ¯ç†µçš„ç‰¹å¾ç¼–å·
    infogain = 0.0  # æœ€ä½³ä¿¡æ¯å¢žç›ŠçŽ‡
    for i in range(numFeatures):
        unique_values = set([line[i] for line in dataSet])  # èŽ·å–æ•°æ®é›†ä¸­å½“å‰ç‰¹å¾çš„æ‰€æœ‰å€¼
        new_ent = 0.0
        s = 0.0
        for value in unique_values:  # éåŽ†æ­¤ç‰¹å¾æ‰€æœ‰çš„å€¼
            sub_dataset = splitDataSet(dataSet, i, value)  # æŒ‰ç…§è¿™ä¸ªå€¼ï¼ŒèŽ·å¾—å­æ•°æ®é›†
            prob = len(sub_dataset) / len(dataSet)  # å­æ•°æ®é›†çš„é•¿åº¦ å°±æ˜¯ æ­¤ç‰¹å¾iå€¼ä¸ºvalueæ—¶çš„æ•°æ®ä¸ªæ•°
            new_ent += prob * calcShannonEnt(sub_dataset)  # ä¾‹ï¼šð‘”(ð‘|ð´)
            a = prob * log(prob, 2)
            if a == 0:
                a = 0.00000000000000001
            s -= a  # ä¾‹ï¼šð‘†ð‘ð‘™ð‘–ð‘¡ð¼ð‘›ð‘“ð‘œð‘Ÿ_ð´ (ð‘)
        gain = ent - new_ent  # è®¡ç®—ä¿¡æ¯å¢žç›Š
        infogain = gain / s  # è®¡ç®—ä¿¡æ¯å¢žç›ŠçŽ‡
        if infogain > best_gain:  # å¦‚æžœæ­¤ä¿¡æ¯å¢žç›ŠçŽ‡æ›´å¤§
            best_gain = infogain  # æ›´æ–°
            best_feature_id = i
    return best_feature_id


# é¢‘çŽ‡æœ€é«˜çš„ç±»åˆ«å‡½æ•° åˆ¤æ–­é€’å½’ä½•æ—¶ç»“æŸ
def majorityCnt(classList):                 #å‚æ•°classListåœ¨ä¸‹é¢åˆ›å»ºæ ‘çš„ä»£ç é‡Œï¼Œæ˜¯æ¯ä¸€è¡Œçš„æœ€åŽä¸€ä¸ªç‰¹å¾
    classCount = {}
    for vote in classList:                   #å°†ç‰¹å¾é‡Œçš„å…ƒç´ æ·»åŠ åˆ°æ–°å»ºçš„å­—å…¸é‡Œä½œä¸ºé”®å€¼ï¼Œå¹¶ç»Ÿè®¡è¯¥é”®å€¼å‡ºçŽ°æ¬¡æ•°
        if vote not in classCount.keys(): classCount[vote] = 0
        classCount[vote] += 1
    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)
    return sortedClassCount[0][0]           #è¿”å›žå‡ºçŽ°æ¬¡æ•°æœ€å¤šçš„é”®å€¼


# åˆ›å»ºå†³ç­–æ ‘
def createTree(dataset, labels):
    Lab = copy.deepcopy(labels)
    class_list = [data[-1] for data in dataset]  # èŽ·å–å½“å‰æ•°æ®é›†æ¯è¡Œçš„åˆ†ç±»æ ‡ç­¾ï¼Œè´·æ¬¾æ˜¯/å¦
    if class_list.count(class_list[0]) == len(class_list):
        # å¦‚æžœå½“å‰æ•°æ®é›†ä¸­ï¼Œå±žäºŽåŒä¸€ç±»ï¼Œåˆ™é€€å‡ºé€’å½’
        return class_list[0]  # è¿”å›žæ­¤ç±»çš„æ ‡ç­¾

    # èŽ·å–æœ€å¥½çš„åˆ†ç±»ç‰¹å¾ç´¢å¼•
    best_feature_id = chooseBestFeatureToSplit_rate(dataset)  # ç¼–å·ä¸º2
    # èŽ·å–è¯¥ç‰¹å¾çš„åå­—
    best_feature_label = Lab[best_feature_id]  # ç‰¹å¾åä¸ºï¼šè½¦å¦

    # è¿™é‡Œç›´æŽ¥ä½¿ç”¨å­—å…¸å˜é‡æ¥å­˜å‚¨æ ‘ä¿¡æ¯ï¼Œè¿™å¯¹äºŽå›žæ‰§æ ‘å½¢å›¾å¾ˆé‡è¦
    my_tree = {best_feature_label: {}}  # å½“å‰æ•°æ®é›†é€‰å–æœ€å¥½çš„ç‰¹å¾å­˜å‚¨åœ¨bestFeatä¸­
    del (Lab[best_feature_id])  # åˆ é™¤å·²ç»åœ¨é€‰å–çš„ç‰¹å¾  æ­¤æ—¶  labels = ['æ˜¯å¦æœ‰è½¦']

    # å–å‡ºæœ€ä¼˜åˆ—çš„å€¼
    feature_values_set = set([data[best_feature_id] for data in dataset])  # ['æ˜¯', 'å¦']
    for value in feature_values_set:  # å¯¹äºŽæ­¤ç‰¹å¾çš„æ¯ä¸€ä¸ªå–å€¼
        temp = splitDataSet(dataset, best_feature_id, value)  # åˆ‡åˆ†æ•°æ®é›†ï¼Œè¿›è¡Œåˆ†æ”¯
        my_tree[best_feature_label][value] = createTree(temp, Lab)  # å¯¹äºŽæ¯ä¸€ä¸ªå­èŠ‚ç‚¹é€’å½’å»ºæ ‘
    return my_tree


def show_result(node, class_label, step=0):
    if type(node) == bool:
        node = str(node)
        if type(node) == str:
            print('-'*step + class_label + "ï¼š" + node)
            return
    for k1, v1 in node.items():
        for k2, v2 in v1.items():
            print('-'*step + k1 + ':' + str(k2))
            show_result(v2, class_label, step+1)


def get_class(node, data, step=0): # é€’å½’å‡½æ•°
    if type(node) == bool: # å¦‚æžœå½“å‰ç»“ç‚¹ç±»åž‹ä¸ºstrï¼Œè€Œä¸æ˜¯dictï¼Œè¯´æ˜Žæ‰¾åˆ°ç»“æžœäº†
        return node # è¿”å›žç»“æžœ
    for k1, v1 in node.items(): # æ‰¾åˆ°ç‰¹å¾åç§°
        for k2, v2 in v1.items(): # æ‰¾åˆ°å†³ç­–æ ‘ä¸­æ­¤ç‰¹å¾çš„å–å€¼
            if data[k1] == k2: # å¦‚æžœå½“å‰æ•°æ®ä¸­æ­¤ç‰¹å¾çš„å€¼ç­‰äºŽk2
                res = get_class(v2, data, step+1) # é€’å½’
                if res != None: # å¦‚æžœæ‰¾åˆ°çš„ç»“æžœä¸æ˜¯Noneï¼Œåˆ™ä¸€å®šæ˜¯â€œæ˜¯â€æˆ–â€œå¦â€
                    return res  # ç›´æŽ¥è¿”å›ž


def predict_acc(test_res_list, res_list):
    #################################
    # test_res_list:æµ‹è¯•é›†çš„æ­£ç¡®ç­”æ¡ˆ
    # res_list:å¾—åˆ°çš„ç­”æ¡ˆ
    #################################
    TN = 0
    FN = 0
    TP = 0
    FP = 0
    for i in range(len(test_res_list)):
        if not test_res_list[i]:
            if not res_list[i] and res_list[i] is not None:
                TN += 1
            else:
                FN += 1
        if test_res_list[i]:
            if res_list[i] and res_list[i] is not None:
                TP += 1
            else:
                FP += 1
    acc = (TN + TP)/(TN + TP + FN + FP)
    P = TP / (TP + FP)
    R = TP / (TP + FN)
    F1 = (2*P*R)/(P+R)
    return acc, F1


def Vote_Tree(res_list, test_res_list):
    res = []
    T = 0
    F = 0
    compare = []
    for i in range(len(res_list[0])):
        for j in range(len(res_list)):
            compare.append(res_list[j][i])
            if j == len(res_list)-1:
                for k in compare:
                    if k:
                        T += 1
                    elif not k:
                        F += 1
                if T > F:
                    res.append(True)
                elif T < F:
                    res.append(False)
                elif T == F:
                    res.append(None)
                compare = []
                T = 0
                F = 0
    acc, F1 = predict_acc(test_res_list[0], res)
    print('å¤šæ£µå†³ç­–æ ‘æŠ•ç¥¨å®Œæˆï¼Œæœ€ç»ˆç»“æžœä¸ºï¼š'+'\n')
    print(res)
    print('acc:'+str(acc)+'\n'+'F1:'+str(F1))



# é¢„æµ‹ä¸»å‡½æ•°
def predict(test_dataset, my_tree, labels):
    res_list = []
    test_res_list = []
    print("ä½¿ç”¨å†³ç­–æ ‘é¢„æµ‹ï¼š")
    for i in range(len(test_dataset)): # éåŽ†æµ‹è¯•é›†
        data = {} # å°†æµ‹è¯•é›†çš„æ¯ä¸€è¡Œæ•°æ®ï¼Œåšä¸ªç‰¹å¾åˆ°ç‰¹å¾å€¼çš„æ˜ å°„
        for j in range(len(test_dataset[i])-1):
            data[labels[j]] = test_dataset[i][j]
        test_res_list.append(test_dataset[i][20])
        res = get_class(my_tree, data) # æ ¹æ®å†³ç­–æ ‘ï¼Œæ‰¾åˆ°ç»“æžœ
        res_list.append(res)
        # print(test_dataset[i], res) # æ‰“å°ç»“æžœ
    acc, F1 = predict_acc(test_res_list, res_list)
    print('acc:'+str(acc)+'\n'+'F1:'+str(F1))
    return res_list, test_res_list, acc, F1



